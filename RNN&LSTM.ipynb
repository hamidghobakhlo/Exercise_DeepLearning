{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhZpIvBUw2rq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKaUKiTJzMaY"
      },
      "outputs": [],
      "source": [
        "max_features = 10000\n",
        "max_len = 500\n",
        "batch_size = 32\n",
        "embedding_size = 128\n",
        "rnn_units = 64\n",
        "lstm_units = 64\n",
        "epochs = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-irmbgGuzPkS",
        "outputId": "d99a03e1-2ca9-4b2f-86e7-37803905f255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv2fGRFu0Qdn",
        "outputId": "1acc3c45-7e87-4d5f-a0dc-ac1359ea5d0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   19,  178,   32],\n",
              "       [   0,    0,    0, ...,   16,  145,   95],\n",
              "       [   0,    0,    0, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4, 3586,    2],\n",
              "       [   0,    0,    0, ...,   12,    9,   23],\n",
              "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oQqRZN60SM0",
        "outputId": "6523f72a-83bb-4e10-9378-b363de8d0b9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb3FSt6P0YTQ"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add(Embedding(max_features, embedding_size, input_length=max_len))\n",
        "# model.add(SimpleRNN(rnn_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#LSTM\n",
        "model.add(Embedding(max_features, embedding_size, input_length=max_len))\n",
        "model.add(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa1UBiij2jQp"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swZ_Dlic3Daj",
        "outputId": "8c142306-0e1c-448d-a5fb-7c4545b6614c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 320s 406ms/step - loss: 0.4294 - accuracy: 0.7998 - val_loss: 0.3620 - val_accuracy: 0.8491\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 317s 405ms/step - loss: 0.2781 - accuracy: 0.8884 - val_loss: 0.3226 - val_accuracy: 0.8702\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 317s 406ms/step - loss: 0.1962 - accuracy: 0.9263 - val_loss: 0.3249 - val_accuracy: 0.8625\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ad2d724a740>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grwTQraE3PI8",
        "outputId": "8792094d-15cf-45bb-fae8-727771b2f96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 46s 59ms/step - loss: 0.3249 - accuracy: 0.8625\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.32485276460647583, 0.8624799847602844]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we21WxKA61Uf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-dGQBMi5w9k",
        "outputId": "f0d42908-0b25-4a68-e663-0d77d5c90576"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 274ms/step\n",
            "Sentence: 'hate'\n",
            "Predicted sentiment: negative (Score: 0.45256146788597107)\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Sentence: 'I love it'\n",
            "Predicted sentiment: negative (Score: 0.44641581177711487)\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Sentence: 'love'\n",
            "Predicted sentiment: negative (Score: 0.45256146788597107)\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Sentence: 'bad'\n",
            "Predicted sentiment: negative (Score: 0.45256146788597107)\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Sentence: 'like'\n",
            "Predicted sentiment: negative (Score: 0.45256146788597107)\n"
          ]
        }
      ],
      "source": [
        "def predict_sentiment(sentence):\n",
        "    # Tokenize the sentence\n",
        "    tokenizer = Tokenizer(num_words=max_features)\n",
        "    tokenizer.fit_on_texts([sentence])\n",
        "    sequence_data = tokenizer.texts_to_sequences([sentence])\n",
        "\n",
        "    # Pad the sequence\n",
        "    padded_sequence = pad_sequences(sequence_data, maxlen=max_len)\n",
        "\n",
        "    # Predict sentiment\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n",
        "\n",
        "    return sentiment, prediction[0][0]\n",
        "\n",
        "# Example usage\n",
        "while True:\n",
        "    sentence = input(\"Enter a sentence (or 'exit' to quit): \")\n",
        "    if sentence.lower() == 'exit':\n",
        "        break\n",
        "    sentiment, score = predict_sentiment(sentence)\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"Predicted sentiment: {sentiment} (Score: {score})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lX6bJEHTt8No"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}